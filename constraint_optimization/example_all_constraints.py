"""
–ú–∏–Ω–∏-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ L1, L2 –∏ L‚àû –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞–º–∏ Frank‚ÄìWolfe, Projected Gradient –∏ N-Conjugate FW.
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as T
import matplotlib.pyplot as plt
from tqdm import tqdm

from models.small_cnn import SmallCNN
from sets.l1_constraint import L1ConstraintSet
from sets.l2_constraint import L2ConstraintSet
from sets.linf_constraint import LinfConstraintSet
from optim.frank_wolfe import FrankWolfe
from optim.projected_grad import ProjectedGradient
from optim.n_conjugate_frank_wolfe import NConjugateFrankWolfe  # üî• –Ω–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä


# ======================= –£—Ç–∏–ª–∏—Ç—ã =======================
def train(model, opt, data, loss_fn, device, epochs=10):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Å tqdm-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º."""
    model.train()
    losses = []
    for epoch in range(epochs):
        pbar = tqdm(data, desc=f"Epoch {epoch+1}/{epochs}", leave=False)
        for x, y in pbar:
            x, y = x.to(device), y.to(device)

            def closure():
                opt.zero_grad()
                out = model(x)
                loss = loss_fn(out, y)
                loss.backward()
                return loss

            loss = opt.step(closure)
            losses.append(loss)
            pbar.set_postfix({"loss": f"{loss:.4f}"})
    return losses


def norms(model):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç L1, L2, L‚àû –Ω–æ—Ä–º—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    return {
        name: dict(
            l1=param.abs().sum().item(),
            l2=param.norm().item(),
            linf=param.abs().max().item(),
        )
        for name, param in model.named_parameters()
    }


def check(feas, tau, typ):
    for name, ok in feas.items():
        print(f"{typ} {name}: {'‚úì' if ok else '‚úó'}")


def evaluate_constraint_strength(model, tau_dict):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–ª–∏ –±–æ–ª—å—à–∏–µ —Ä–∞–¥–∏—É—Å—ã –º–Ω–æ–∂–µ—Å—Ç–≤."""
    norms_ = norms(model)
    for name, n in norms_.items():
        t = tau_dict[name]
        ratio_l1 = n["l1"] / t
        ratio_l2 = n["l2"] / t
        if ratio_l1 < 0.1 and ratio_l2 < 0.1:
            print(f"‚ö†Ô∏è {name}: —Ä–∞–¥–∏—É—Å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ)")
        elif ratio_l1 > 1.5 or ratio_l2 > 1.5:
            print(f"‚ö†Ô∏è {name}: —Ä–∞–¥–∏—É—Å —Å–ª–∏—à–∫–æ–º –º–∞–ª (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–∞–∂–∏–º–∞–µ—Ç –≤–µ—Å–∞)")
    return norms_


# ======================= –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ =======================
def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}\n")

    # --- –î–∞–Ω–Ω—ã–µ ---
    ds = torchvision.datasets.MNIST("./data", train=True, download=True, transform=T.ToTensor())
    loader = torch.utils.data.DataLoader(
        torch.utils.data.Subset(ds, range(2000)), batch_size=64, shuffle=True
    )
    loss_fn = nn.CrossEntropyLoss()

    # --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ---
    constraints = {
        "L1": (L1ConstraintSet, 1.0),
        "L2": (L2ConstraintSet, 5.0),
        "L‚àû": (LinfConstraintSet, 0.1),
    }
    opts = {
        "FW": FrankWolfe,
        "PG": ProjectedGradient,
        "NFW": lambda params, C: NConjugateFrankWolfe(
            params, C,
            n_conjugates=3,
            lr=0.1,
            use_real_hessian=False,
            use_line_search=True,  # –º–æ–∂–Ω–æ –∏ False
        ),
    }

    results = {}
    for cname, (Cset, tau_val) in constraints.items():
        for oname, Opt in opts.items():
            key = f"{cname}+{oname}"
            print(f"\n=== {key} ===")
            model = SmallCNN().to(device)
            tau = {n: tau_val for n, _ in model.named_parameters()}
            C = Cset(model, tau)

            # –ø–æ–¥–¥–µ—Ä–∂–∫–∞ lambda –¥–ª—è NFW
            if callable(Opt):
                opt = Opt([{"params": model.parameters(), "params_dict": dict(model.named_parameters())}], C)
            else:
                opt = Opt(
                    [{"params": model.parameters(), "params_dict": dict(model.named_parameters())}],
                    C, lr=0.05
                )

            losses = train(model, opt, loader, loss_fn, device, epochs=20)
            results[key] = dict(
                losses=losses,
                norms=evaluate_constraint_strength(model, tau),
                constraint=C,
                model=model,
                tau=tau,
            )
            print(f"Final loss = {losses[-1]:.3f}")

        # --- üìä –û—Ç–¥–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ ---
    for cname in constraints.keys():
        plt.figure(figsize=(7, 5))
        for oname in opts.keys():
            key = f"{cname}+{oname}"
            if key in results:
                plt.plot(results[key]["losses"], label=oname)
        plt.xlabel("Iteration")
        plt.ylabel("Loss")
        plt.title(f"{cname}-Constraint: Comparison of Optimizers")
        plt.legend()
        plt.grid(alpha=0.3)
        plt.tight_layout()
        filename = f"comparison_{cname.replace('‚àû','inf')}.png"
        plt.savefig(filename, dpi=150)
        plt.close()
        print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –¥–ª—è {cname} —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ {filename}")

    # --- üß© –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –æ–±—â–∏–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –≤—Å–µ—Ö ---
    plt.figure(figsize=(7, 5))
    for k, r in results.items():
        plt.plot(r["losses"], label=k)
    plt.xlabel("Iteration")
    plt.ylabel("Loss")
    plt.title("All Constraints and Optimizers")
    plt.legend(fontsize=8)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig("comparison_all.png", dpi=150)
    print("\nüìâ –û–±—â–∏–π –≥—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ comparison_all.png")



if __name__ == "__main__":
    main()
