# –§—Ä–µ–π–º–≤–æ—Ä–∫ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è PyTorch

–ú–æ–¥—É–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.

## üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å PyTorch**: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ `nn.Module`
- **–ì–æ—Ç–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã**: Frank-Wolfe –∏ Projected Gradient
- **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å**: –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Ç–∏–ø—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
constraint_optimization/
‚îú‚îÄ‚îÄ main.py                # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞, –æ–±—É—á–µ–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îú‚îÄ‚îÄ sets/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ l1_constraint.py   # –ö–ª–∞—Å—Å –º–Ω–æ–∂–µ—Å—Ç–≤–∞ L1-–Ω–æ—Ä–º—ã
‚îú‚îÄ‚îÄ optim/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ frank_wolfe.py     # –ö–ª–∞—Å—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ Frank-Wolfe
‚îÇ   ‚îî‚îÄ‚îÄ projected_grad.py  # –ö–ª–∞—Å—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ Projected Gradient
‚îî‚îÄ‚îÄ models/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ small_cnn.py       # –ù–µ–±–æ–ª—å—à–∞—è CNN –¥–ª—è MNIST
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

### –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

```bash
python main.py
```

–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
1. –ó–∞–≥—Ä—É–∑–∏—Ç –¥–∞—Ç–∞—Å–µ—Ç MNIST
2. –û–±—É—á–∏—Ç –¥–≤–µ –º–æ–¥–µ–ª–∏ (—Å Frank-Wolfe –∏ Projected Gradient)
3. –ü–æ—Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
4. –°–æ—Ö—Ä–∞–Ω–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ `optimization_comparison.png`

## üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ü—Ä–∏–º–µ—Ä —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é

```python
from constraint_optimization.models import SmallCNN
from constraint_optimization.sets import L1ConstraintSet
from constraint_optimization.optim import FrankWolfe

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = SmallCNN()

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: ||w||_1 <= tau –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
tau = {name: 5.0 for name, _ in model.named_parameters()}
constraint = L1ConstraintSet(model, tau)

# –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
optimizer = FrankWolfe(
    [{"params": model.parameters(), 
      "params_dict": dict(model.named_parameters())}], 
    constraint, 
    lr=0.05
)

# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
for inputs, targets in dataloader:
    def closure():
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        return loss
    
    loss = optimizer.step(closure)
```

## üîß –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### –ú–Ω–æ–∂–µ—Å—Ç–≤–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (sets)

#### `L1ConstraintSet`

–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ L1-–Ω–æ—Ä–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \(\|w\|_1 \leq \tau\)

**–ú–µ—Ç–æ–¥—ã:**
- `lmo(grad_dict)` ‚Äî Linear Minimization Oracle –¥–ª—è Frank-Wolfe
- `project(param_dict)` ‚Äî –ø—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è Projected Gradient

### –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã (optim)

#### `FrankWolfe`

–ú–µ—Ç–æ–¥ —É—Å–ª–æ–≤–Ω–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (Conditional Gradient):
\[
w_{t+1} = (1 - \alpha_t) w_t + \alpha_t s_t
\]
–≥–¥–µ \(s_t = \arg\min_{s \in \mathcal{C}} \langle \nabla f(w_t), s \rangle\)

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `lr` ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (\(\alpha_t\))

#### `ProjectedGradient`

–ü—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫:
\[
w_{t+1} = \Pi_{\mathcal{C}}(w_t - \alpha_t \nabla f(w_t))
\]

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `lr` ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ `main.py` –≤—ã —É–≤–∏–¥–∏—Ç–µ:

- –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–±–æ–∏—Ö –º–µ—Ç–æ–¥–æ–≤
- –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –§–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è loss
- L1-–Ω–æ—Ä–º—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–¥–æ–ª–∂–Ω—ã —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—é \(\leq \tau\))

## üé® –†–∞—Å—à–∏—Ä–µ–Ω–∏—è

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç–∏–ø–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π

–°–æ–∑–¥–∞–π—Ç–µ –∫–ª–∞—Å—Å –≤ `sets/` —Å –º–µ—Ç–æ–¥–∞–º–∏:
- `lmo(grad_dict)` ‚Äî –¥–ª—è Frank-Wolfe
- `project(param_dict)` ‚Äî –¥–ª—è Projected Gradient

–ü—Ä–∏–º–µ—Ä –¥–ª—è L2-—à–∞—Ä–∞:

```python
class L2ConstraintSet:
    def __init__(self, model, tau_per_param):
        self.tau = tau_per_param
    
    def lmo(self, grad_dict):
        # –î–ª—è L2: s = -tau * grad / ||grad||_2
        s = {}
        for name, g in grad_dict.items():
            norm = torch.norm(g)
            s[name] = -self.tau[name] * g / (norm + 1e-8)
        return s
    
    def project(self, param_dict):
        # –ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ L2-—à–∞—Ä
        proj = {}
        for name, p in param_dict.items():
            norm = torch.norm(p)
            if norm <= self.tau[name]:
                proj[name] = p.clone()
            else:
                proj[name] = self.tau[name] * p / norm
        return proj
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

–ù–∞—Å–ª–µ–¥—É–π—Ç–µ—Å—å –æ—Ç `torch.optim.Optimizer` –∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç–æ–¥ `step(closure)`.

## üìù –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

- **Frank-Wolfe**: Jaggi, M. (2013). "Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization"
- **Projected Gradient**: Bertsekas, D. (1999). "Nonlinear Programming"

## ü§ù –í–∫–ª–∞–¥

–í—ã –º–æ–∂–µ—Ç–µ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫:
- –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Ç–∏–ø—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (L‚àû, nuclear norm, etc.)
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–±–æ—Ä–∞ —à–∞–≥–∞
- –î–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow/Weights & Biases
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ—Ä—Å–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

